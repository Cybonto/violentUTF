# Copyright (c) 2025 ViolentUTF Contributors.
# Licensed under the MIT License.
#
# This file is part of ViolentUTF - An AI Red Teaming Platform.
# See LICENSE file in the project root for license information.

"""
Vulnerability Assessment Service with NIST NVD Integration

This module provides comprehensive vulnerability assessment capabilities
integrating with the NIST National Vulnerability Database (NVD) for real-time
CVE analysis, CVSS scoring, and automated remediation recommendations.

Key Features:
- NIST NVD integration using nvdlib
- CPE identifier generation for database assets
- CVSS score analysis and vulnerability scoring
- Exploit availability checking
- Remediation recommendation engine
- Performance optimization with caching

Performance Requirements:
- Vulnerability scan: ≤ 10 minutes per asset
- CPE generation: ≤ 100ms per asset
- Cache hit rate: ≥ 80% for repeated queries
"""

import asyncio
import hashlib
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

# External dependencies (would be installed in production)
try:
    import nvdlib

    NVDLIB_AVAILABLE = True
except ImportError:
    NVDLIB_AVAILABLE = False
    logging.warning("nvdlib not available - using mock vulnerability data")

from app.models.risk_assessment import DatabaseAsset, VulnerabilitySeverity

# Configure logging
logger = logging.getLogger(__name__)


@dataclass
class Vulnerability:
    """Individual vulnerability record from NIST NVD"""

    cve_id: str
    description: str
    cvss_score: float
    severity: VulnerabilitySeverity
    published_date: datetime
    last_modified: datetime
    cpe_matches: List[str]
    references: List[str]
    cwe_ids: List[str]
    exploit_available: bool = False


@dataclass
class RemediationRecommendation:
    """Prioritized remediation recommendation"""

    priority: int
    action: str  # VERSION_UPGRADE, CONFIGURATION_CHANGE, SECURITY_PATCH, etc.
    description: str
    affected_vulnerabilities: List[str]
    estimated_effort_hours: int
    business_impact: str  # LOW, MEDIUM, HIGH
    technical_complexity: str  # LOW, MEDIUM, HIGH


@dataclass
class VulnerabilityAssessment:
    """Complete vulnerability assessment result"""

    asset_id: str
    assessment_date: datetime
    vulnerabilities: List[Vulnerability]
    total_vulnerabilities: int
    critical_vulnerabilities: int
    high_vulnerabilities: int
    medium_vulnerabilities: int
    low_vulnerabilities: int
    vulnerability_score: float  # 1-5 scale
    remediation_recommendations: List[RemediationRecommendation]
    next_scan_date: datetime
    scan_duration_seconds: Optional[int] = None


class VulnerabilityAssessmentService:
    """
    Comprehensive vulnerability assessment service with NIST NVD integration

    Provides automated vulnerability scanning, scoring, and remediation
    recommendations for database assets with high performance and accuracy.
    """

    def __init__(self, nvd_api_key: Optional[str] = None, cache_duration_hours: int = 24) -> None:
        """Initialize vulnerability assessment service with optional NVD API key."""
        self.nvd_api_key = nvd_api_key
        self.cache_duration_hours = cache_duration_hours
        self.vulnerability_cache: Dict[str, Any] = {}

        # Version information for remediation recommendations
        self.latest_versions = {
            "postgresql": "15.4",
            "sqlite": "3.43.1",
            "duckdb": "0.9.1",
            "mysql": "8.1.0",
            "mongodb": "7.0.2",
        }

        logger.info("VulnerabilityAssessmentService initialized with NVD API: %s", bool(nvd_api_key))

    async def assess_asset_vulnerabilities(self, asset: DatabaseAsset) -> VulnerabilityAssessment:
        """
        Perform comprehensive vulnerability assessment for database asset

        Args:
            asset: Database asset to assess

        Returns:
            Complete vulnerability assessment with scoring and recommendations

        Raises:
            ValueError: If asset data is invalid
            Exception: If vulnerability scanning fails
        """
        start_time = datetime.utcnow()

        try:
            logger.info("Starting vulnerability assessment for asset %s", asset.id)

            # Validate asset data
            self._validate_asset(asset)

            # Generate CPE identifiers for vulnerability scanning
            cpe_identifiers = await self.generate_cpe_identifiers(asset)

            # Search for vulnerabilities using all CPE identifiers
            all_vulnerabilities = []
            for cpe in cpe_identifiers:
                cpe_vulnerabilities = await self.search_vulnerabilities_by_cpe(cpe)
                all_vulnerabilities.extend(cpe_vulnerabilities)

            # Remove duplicates and sort by severity
            unique_vulnerabilities = self._deduplicate_vulnerabilities(all_vulnerabilities)
            sorted_vulnerabilities = sorted(unique_vulnerabilities, key=lambda v: v.cvss_score, reverse=True)

            # Calculate vulnerability statistics
            vuln_stats = self._calculate_vulnerability_statistics(sorted_vulnerabilities)

            # Calculate overall vulnerability score (1-5 scale)
            vulnerability_score = self.calculate_vulnerability_score(sorted_vulnerabilities)

            # Generate remediation recommendations
            recommendations = await self.generate_remediation_recommendations(asset, sorted_vulnerabilities)

            # Calculate scan duration
            end_time = datetime.utcnow()
            scan_duration = int((end_time - start_time).total_seconds())

            # Performance requirement check (≤ 10 minutes = 600 seconds)
            if scan_duration > 600:
                logger.warning("Vulnerability scan took %ss, exceeding 600s target", scan_duration)

            assessment = VulnerabilityAssessment(
                asset_id=str(asset.id),
                assessment_date=start_time,
                vulnerabilities=sorted_vulnerabilities,
                total_vulnerabilities=vuln_stats["total"],
                critical_vulnerabilities=vuln_stats["critical"],
                high_vulnerabilities=vuln_stats["high"],
                medium_vulnerabilities=vuln_stats["medium"],
                low_vulnerabilities=vuln_stats["low"],
                vulnerability_score=vulnerability_score,
                remediation_recommendations=recommendations,
                next_scan_date=self._calculate_next_scan_date(vulnerability_score),
                scan_duration_seconds=scan_duration,
            )

            logger.info(
                "Vulnerability assessment completed for asset %s: %s vulnerabilities found, score=%s, duration=%ss",
                asset.id,
                vuln_stats["total"],
                vulnerability_score,
                scan_duration,
            )

            return assessment

        except Exception as e:
            logger.error("Error in vulnerability assessment for asset %s: %s", asset.id, e)
            raise

    async def generate_cpe_identifiers(self, asset: DatabaseAsset) -> List[str]:
        """
        Generate CPE (Common Platform Enumeration) identifiers for asset

        CPE format: cpe:2.3:a:vendor:product:version:update:edition:language:sw_edition:target_sw:target_hw:other

        Args:
            asset: Database asset to generate CPEs for

        Returns:
            List of CPE identifiers for vulnerability scanning
        """
        try:
            cpe_identifiers = []

            asset_type_lower = asset.asset_type.lower()

            if asset_type_lower == "postgresql":
                if asset.database_version:
                    # Specific version CPE
                    cpe_identifiers.append(f"cpe:2.3:a:postgresql:postgresql:{asset.database_version}:*:*:*:*:*:*:*")
                else:
                    # Wildcard version for all PostgreSQL vulnerabilities
                    cpe_identifiers.append("cpe:2.3:a:postgresql:postgresql:*:*:*:*:*:*:*:*")

            elif asset_type_lower == "sqlite":
                if asset.database_version:
                    cpe_identifiers.append(f"cpe:2.3:a:sqlite:sqlite:{asset.database_version}:*:*:*:*:*:*:*")
                else:
                    cpe_identifiers.append("cpe:2.3:a:sqlite:sqlite:*:*:*:*:*:*:*:*")

            elif asset_type_lower == "duckdb":
                if asset.database_version:
                    cpe_identifiers.append(f"cpe:2.3:a:duckdb:duckdb:{asset.database_version}:*:*:*:*:*:*:*")
                else:
                    cpe_identifiers.append("cpe:2.3:a:duckdb:duckdb:*:*:*:*:*:*:*:*")

            elif asset_type_lower == "mysql":
                if asset.database_version:
                    cpe_identifiers.append(f"cpe:2.3:a:oracle:mysql:{asset.database_version}:*:*:*:*:*:*:*")
                else:
                    cpe_identifiers.append("cpe:2.3:a:oracle:mysql:*:*:*:*:*:*:*:*")

            elif asset_type_lower == "mongodb":
                if asset.database_version:
                    cpe_identifiers.append(f"cpe:2.3:a:mongodb:mongodb:{asset.database_version}:*:*:*:*:*:*:*")
                else:
                    cpe_identifiers.append("cpe:2.3:a:mongodb:mongodb:*:*:*:*:*:*:*:*")

            logger.debug("Generated %s CPE identifiers for asset %s", len(cpe_identifiers), asset.id)
            return cpe_identifiers

        except Exception as e:
            logger.error("Error generating CPE identifiers for asset %s: %s", asset.id, e)
            return []

    async def search_vulnerabilities_by_cpe(self, cpe_identifier: str) -> List[Vulnerability]:
        """
        Search NIST NVD for vulnerabilities matching CPE identifier

        Uses caching to improve performance and reduce API calls.

        Args:
            cpe_identifier: CPE identifier to search for

        Returns:
            List of vulnerabilities matching the CPE
        """
        try:
            # Check cache first
            cache_key = f"cpe_{hashlib.md5(cpe_identifier.encode(), usedforsecurity=False).hexdigest()}"

            if cache_key in self.vulnerability_cache:
                cache_entry = self.vulnerability_cache[cache_key]
                cache_age = (datetime.utcnow() - cache_entry["timestamp"]).total_seconds()

                if cache_age < self.cache_duration_hours * 3600:
                    logger.debug("Cache hit for CPE %s", cpe_identifier)
                    return cache_entry["vulnerabilities"]
                else:
                    logger.debug("Cache expired for CPE %s", cpe_identifier)

            # Search NVD for vulnerabilities
            vulnerabilities = []

            if NVDLIB_AVAILABLE and self.nvd_api_key:
                # Use real NIST NVD API
                vulnerabilities = await self._search_nvd_api(cpe_identifier)
            else:
                # Use mock vulnerability data for testing/development
                vulnerabilities = await self._get_mock_vulnerabilities(cpe_identifier)

            # Cache the results
            self.vulnerability_cache[cache_key] = {"vulnerabilities": vulnerabilities, "timestamp": datetime.utcnow()}

            logger.debug("Found %s vulnerabilities for CPE %s", len(vulnerabilities), cpe_identifier)
            return vulnerabilities

        except Exception as e:
            logger.error("Error searching vulnerabilities for CPE %s: %s", cpe_identifier, e)
            return []

    async def _search_nvd_api(self, cpe_identifier: str) -> List[Vulnerability]:
        """Search real NIST NVD API for vulnerabilities"""
        try:
            vulnerabilities = []

            # Search NVD using nvdlib
            nvd_results = nvdlib.searchCPE(cpeName=cpe_identifier, key=self.nvd_api_key)

            for nvd_vuln in nvd_results:
                # Check exploit availability
                exploit_available = await self.check_exploit_availability(nvd_vuln.id)

                vulnerability = Vulnerability(
                    cve_id=nvd_vuln.id,
                    description=nvd_vuln.description,
                    cvss_score=nvd_vuln.score if nvd_vuln.score else 0.0,
                    severity=self.map_cvss_to_severity(nvd_vuln.score if nvd_vuln.score else 0.0),
                    published_date=nvd_vuln.published,
                    last_modified=nvd_vuln.lastModified,
                    cpe_matches=[cpe_identifier],
                    references=nvd_vuln.references if hasattr(nvd_vuln, "references") else [],
                    cwe_ids=nvd_vuln.cwe if hasattr(nvd_vuln, "cwe") else [],
                    exploit_available=exploit_available,
                )
                vulnerabilities.append(vulnerability)

            return vulnerabilities

        except Exception as e:
            logger.error("Error searching NVD API: %s", e)
            return []

    async def _get_mock_vulnerabilities(self, cpe_identifier: str) -> List[Vulnerability]:
        """Generate mock vulnerability data for testing/development"""
        mock_vulnerabilities = []

        # Generate realistic mock data based on CPE
        if "postgresql" in cpe_identifier:
            mock_vulnerabilities = [
                Vulnerability(
                    cve_id="CVE-2023-39417",
                    description="SQL injection vulnerability in PostgreSQL extension",
                    cvss_score=9.8,
                    severity=VulnerabilitySeverity.CRITICAL,
                    published_date=datetime(2023, 8, 15),
                    last_modified=datetime(2023, 8, 20),
                    cpe_matches=[cpe_identifier],
                    references=["https://postgresql.org/security/CVE-2023-39417"],
                    cwe_ids=["CWE-89"],
                    exploit_available=True,
                ),
                Vulnerability(
                    cve_id="CVE-2023-39418",
                    description="Authentication bypass in database connection handler",
                    cvss_score=7.5,
                    severity=VulnerabilitySeverity.HIGH,
                    published_date=datetime(2023, 7, 20),
                    last_modified=datetime(2023, 7, 25),
                    cpe_matches=[cpe_identifier],
                    references=["https://postgresql.org/security/CVE-2023-39418"],
                    cwe_ids=["CWE-287"],
                    exploit_available=False,
                ),
            ]

        elif "sqlite" in cpe_identifier:
            mock_vulnerabilities = [
                Vulnerability(
                    cve_id="CVE-2023-36191",
                    description="Information disclosure in SQLite FTS module",
                    cvss_score=5.2,
                    severity=VulnerabilitySeverity.MEDIUM,
                    published_date=datetime(2023, 6, 10),
                    last_modified=datetime(2023, 6, 15),
                    cpe_matches=[cpe_identifier],
                    references=["https://sqlite.org/security"],
                    cwe_ids=["CWE-200"],
                    exploit_available=False,
                )
            ]

        elif "duckdb" in cpe_identifier:
            mock_vulnerabilities = [
                Vulnerability(
                    cve_id="CVE-2023-45678",
                    description="Buffer overflow in DuckDB query parser",
                    cvss_score=6.8,
                    severity=VulnerabilitySeverity.MEDIUM,
                    published_date=datetime(2023, 9, 5),
                    last_modified=datetime(2023, 9, 10),
                    cpe_matches=[cpe_identifier],
                    references=["https://duckdb.org/security"],
                    cwe_ids=["CWE-120"],
                    exploit_available=False,
                )
            ]

        # Simulate API delay
        await asyncio.sleep(0.1)

        return mock_vulnerabilities

    def calculate_vulnerability_score(self, vulnerabilities: List[Vulnerability]) -> float:
        """
        Calculate overall vulnerability score (1-5 scale)

        Considers vulnerability severity, exploitability, and recency.

        Args:
            vulnerabilities: List of vulnerabilities to score

        Returns:
            Vulnerability score between 1.0 and 5.0
        """
        if not vulnerabilities:
            return 1.0  # No vulnerabilities = lowest score

        try:
            weighted_score = 0.0
            total_weight = 0.0

            for vuln in vulnerabilities:
                # Base weight from CVSS score (normalized to 0-1)
                base_weight = vuln.cvss_score / 10.0

                # Increase weight for exploitable vulnerabilities
                if vuln.exploit_available:
                    base_weight *= 1.5

                # Increase weight for recent vulnerabilities (higher threat)
                days_since_published = (datetime.utcnow() - vuln.published_date).days
                if days_since_published <= 30:  # Very recent
                    base_weight *= 1.3
                elif days_since_published <= 90:  # Recent
                    base_weight *= 1.1

                # Weight by severity
                severity_multiplier = {
                    VulnerabilitySeverity.CRITICAL: 1.0,
                    VulnerabilitySeverity.HIGH: 0.8,
                    VulnerabilitySeverity.MEDIUM: 0.6,
                    VulnerabilitySeverity.LOW: 0.4,
                    VulnerabilitySeverity.NONE: 0.1,
                }.get(vuln.severity, 0.6)

                # Calculate weighted contribution
                contribution = (vuln.cvss_score / 10.0) * 5.0 * base_weight * severity_multiplier
                weighted_score += contribution
                total_weight += base_weight

            if total_weight == 0:
                return 1.0

            # Calculate average weighted score and normalize to 1-5 scale
            average_score = weighted_score / total_weight
            normalized_score = max(1.0, min(5.0, average_score))

            return round(normalized_score, 1)

        except Exception as e:
            logger.error("Error calculating vulnerability score: %s", e)
            return 3.0  # Default to medium score on error

    def map_cvss_to_severity(self, cvss_score: float) -> VulnerabilitySeverity:
        """Map CVSS score to vulnerability severity level"""
        if cvss_score == 0.0:
            return VulnerabilitySeverity.NONE
        elif cvss_score < 4.0:
            return VulnerabilitySeverity.LOW
        elif cvss_score < 7.0:
            return VulnerabilitySeverity.MEDIUM
        elif cvss_score < 9.0:
            return VulnerabilitySeverity.HIGH
        else:
            return VulnerabilitySeverity.CRITICAL

    async def check_exploit_availability(self, cve_id: str) -> bool:
        """
        Check if exploits are available for a CVE

        In production, this would integrate with exploit databases
        like ExploitDB, Metasploit, etc.

        Args:
            cve_id: CVE identifier to check

        Returns:
            True if exploits are available, False otherwise
        """
        # Mock implementation - in production would check exploit databases
        high_profile_cves = [
            "CVE-2023-39417",  # Mock critical PostgreSQL SQLi
            "CVE-2021-44228",  # Log4j
            "CVE-2022-22965",  # Spring4Shell
        ]

        return cve_id in high_profile_cves

    async def generate_remediation_recommendations(
        self, asset: DatabaseAsset, vulnerabilities: List[Vulnerability]
    ) -> List[RemediationRecommendation]:
        """
        Generate prioritized remediation recommendations

        Args:
            asset: Database asset being assessed
            vulnerabilities: List of vulnerabilities found

        Returns:
            Prioritized list of remediation recommendations
        """
        try:
            recommendations = []
            priority = 1

            if not vulnerabilities:
                return recommendations

            # Group vulnerabilities by remediation strategy
            version_upgrade_vulns = [v for v in vulnerabilities if self._requires_version_upgrade(v)]
            config_change_vulns = [v for v in vulnerabilities if self._requires_config_change(v)]
            patch_vulns = [v for v in vulnerabilities if self._requires_patch(v)]

            # Version upgrade recommendation
            if version_upgrade_vulns:
                latest_version = await self.get_latest_version(asset.asset_type)
                if latest_version and latest_version != asset.database_version:
                    recommendations.append(
                        RemediationRecommendation(
                            priority=priority,
                            action="VERSION_UPGRADE",
                            description=f"Upgrade {asset.asset_type} from {asset.database_version} to {latest_version}",
                            affected_vulnerabilities=[v.cve_id for v in version_upgrade_vulns],
                            estimated_effort_hours=self._estimate_upgrade_effort(asset),
                            business_impact=self._assess_upgrade_business_impact(asset),
                            technical_complexity="MEDIUM",
                        )
                    )
                    priority += 1

            # Configuration change recommendations
            if config_change_vulns:
                recommendations.append(
                    RemediationRecommendation(
                        priority=priority,
                        action="CONFIGURATION_CHANGE",
                        description="Apply security configuration hardening based on identified vulnerabilities",
                        affected_vulnerabilities=[v.cve_id for v in config_change_vulns],
                        estimated_effort_hours=4,
                        business_impact="LOW",
                        technical_complexity="LOW",
                    )
                )
                priority += 1

            # Security patch recommendations
            if patch_vulns:
                recommendations.append(
                    RemediationRecommendation(
                        priority=priority,
                        action="SECURITY_PATCH",
                        description="Apply available security patches and updates",
                        affected_vulnerabilities=[v.cve_id for v in patch_vulns],
                        estimated_effort_hours=2,
                        business_impact="LOW",
                        technical_complexity="LOW",
                    )
                )
                priority += 1

            # Critical vulnerability immediate action
            critical_vulns = [v for v in vulnerabilities if v.severity == VulnerabilitySeverity.CRITICAL]
            if critical_vulns:
                recommendations.append(
                    RemediationRecommendation(
                        priority=1,  # Highest priority
                        action="IMMEDIATE_MITIGATION",
                        description="Implement immediate mitigations for critical vulnerabilities",
                        affected_vulnerabilities=[v.cve_id for v in critical_vulns],
                        estimated_effort_hours=1,
                        business_impact="HIGH",
                        technical_complexity="LOW",
                    )
                )

            # Sort by priority
            return sorted(recommendations, key=lambda r: r.priority)

        except Exception as e:
            logger.error("Error generating remediation recommendations: %s", e)
            return []

    async def get_latest_version(self, asset_type: str) -> Optional[str]:
        """Get latest version for database type"""
        return self.latest_versions.get(asset_type.lower())

    def _validate_asset(self, asset: DatabaseAsset) -> None:
        """Validate asset data for vulnerability assessment"""
        if not asset.id:
            raise ValueError("Asset ID is required")
        if not asset.name:
            raise ValueError("Asset name is required")
        if not asset.asset_type:
            raise ValueError("Asset type is required")

    def _deduplicate_vulnerabilities(self, vulnerabilities: List[Vulnerability]) -> List[Vulnerability]:
        """Remove duplicate vulnerabilities based on CVE ID"""
        seen_cves = set()
        unique_vulnerabilities = []

        for vuln in vulnerabilities:
            if vuln.cve_id not in seen_cves:
                seen_cves.add(vuln.cve_id)
                unique_vulnerabilities.append(vuln)

        return unique_vulnerabilities

    def _calculate_vulnerability_statistics(self, vulnerabilities: List[Vulnerability]) -> Dict[str, int]:
        """Calculate vulnerability statistics by severity"""
        stats = {"total": len(vulnerabilities), "critical": 0, "high": 0, "medium": 0, "low": 0}

        for vuln in vulnerabilities:
            if vuln.severity == VulnerabilitySeverity.CRITICAL:
                stats["critical"] += 1
            elif vuln.severity == VulnerabilitySeverity.HIGH:
                stats["high"] += 1
            elif vuln.severity == VulnerabilitySeverity.MEDIUM:
                stats["medium"] += 1
            elif vuln.severity == VulnerabilitySeverity.LOW:
                stats["low"] += 1

        return stats

    def _calculate_next_scan_date(self, vulnerability_score: float) -> datetime:
        """Calculate next vulnerability scan date based on current score"""
        # Higher scores require more frequent scanning
        if vulnerability_score >= 4.5:  # High risk
            days_until_next = 7  # Weekly
        elif vulnerability_score >= 3.5:  # Medium-high risk
            days_until_next = 14  # Bi-weekly
        elif vulnerability_score >= 2.5:  # Medium risk
            days_until_next = 30  # Monthly
        else:  # Low risk
            days_until_next = 90  # Quarterly

        return datetime.utcnow() + timedelta(days=days_until_next)

    def _requires_version_upgrade(self, vulnerability: Vulnerability) -> bool:
        """Check if vulnerability requires version upgrade"""
        # Simple heuristic - check if description mentions version-specific issues
        version_keywords = ["version", "upgrade", "update", "prior to", "before"]
        return any(keyword in vulnerability.description.lower() for keyword in version_keywords)

    def _requires_config_change(self, vulnerability: Vulnerability) -> bool:
        """Check if vulnerability can be mitigated by configuration changes"""
        config_keywords = ["configuration", "setting", "parameter", "option", "disable", "enable"]
        return any(keyword in vulnerability.description.lower() for keyword in config_keywords)

    def _requires_patch(self, vulnerability: Vulnerability) -> bool:
        """Check if vulnerability requires security patch"""
        patch_keywords = ["patch", "fix", "update", "hotfix"]
        return any(keyword in vulnerability.description.lower() for keyword in patch_keywords)

    def _estimate_upgrade_effort(self, asset: DatabaseAsset) -> int:
        """Estimate effort hours for version upgrade"""
        # Base effort by database type and environment
        base_effort = {"postgresql": 8, "mysql": 6, "sqlite": 2, "duckdb": 3, "mongodb": 5}.get(
            asset.asset_type.lower(), 4
        )

        # Increase effort for production environments
        if asset.environment and asset.environment.lower() in ["prod", "production"]:
            base_effort *= 2

        # Increase effort for critical systems
        if asset.criticality_level == "critical":
            base_effort *= 1.5

        return int(base_effort)

    def _assess_upgrade_business_impact(self, asset: DatabaseAsset) -> str:
        """Assess business impact of version upgrade"""
        if asset.environment and asset.environment.lower() in ["prod", "production"]:
            if asset.criticality_level in ["critical", "high"]:
                return "HIGH"
            else:
                return "MEDIUM"
        else:
            return "LOW"
