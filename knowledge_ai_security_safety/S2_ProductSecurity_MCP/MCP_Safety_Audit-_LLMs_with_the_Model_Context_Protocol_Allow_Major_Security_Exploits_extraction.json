{
  "sciknow-25x1-scientific-papers": [
    {
      "internal_id": "91ca574d82d74528b38e6b88ed227331",
      "title": "MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits",
      "authors": [
        {
          "name": "B Radosevich"
        },
        {
          "name": "J Halloran"
        }
      ],
      "abstract": "To reduce development overhead and enable seamless integration between potential components comprising any given generative AI application, the Model Context Protocol (MCP) (Anthropic, 2025d) has recently been released and, subsequently, widely adapted. The MCP is an open protocol which standardizes API calls to large language models (LLMs), data sources, and agentic tools. Thus, by connecting multiple MCP servers-each defined with a set of tools, resources, and prompts-users are able to define automated workflows fully driven by LLMs. However, we show that the current MCP design carries a wide range of security risks for end-users. In particular, we show that industry-leading LLMs may be coerced to use MCP tools and compromise an AI developer's system through a wide range of attacks, e.g., malicious code execution, remote access control, and credential theft. In order to proactively mitigate the demonstrated (and related) attacks, we introduce a safety auditing tool, McpSafetyScanner , the first such agentic tool to assess the security of an arbitrary MCP server . McpSafetyScanner uses several agents to: a) automatically determine adversarial samples given an MCP server's tools and resources, (b) search for related vulnerabilities and remediations given such samples, and (c) generate a security report detailing all findings. Our work thus sheds light on serious security issues with general purpose agentic workflows, while also providing a proactive tool to audit the safety of MCP servers and address detected vulnerabilities prior to deployment.\n\nThe described MCP server auditing tool, MCPSafetyScanner, is freely available at: https://github.com/johnhalloran321/mcpSafetyScanner .",
      "doi": "",
      "publicationDate": "2025",
      "journal": "arXiv preprint arXiv:2504.03767, 2025",
      "volume": "2025",
      "issue": "",
      "pages": "",
      "keywords": [],
      "pdfPath": "/Users/tamnguyen/Documents/AI-Safety_Privacy/S2_ProductSecurity_MCP/MCP Safety Audit- LLMs with the Model Context Protocol Allow Major Security Exploits.pdf",
      "fileUrl": "https://arxiv.org/abs/2504.03767",
      "extractionDate": "2025-04-30T21:58:15.159293",
      "extractionConfidenceScore": 0.8295
    }
  ],
  "sciknow-25x1-research-contexts": [
    {
      "internal_id": "0ef7523b56b64608a9e46db04c870916",
      "discipline": "Computer Science",
      "fieldOfStudy": "Cybersecurity, Artificial Intelligence",
      "associatedProject": null,
      "fundingSources": [],
      "institutions": [],
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331"
    }
  ],
  "sciknow-25x1-theoretical-bases": [
    {
      "internal_id": "19cd1ae28a904067a8607942f9f088e2",
      "underlyingTheories": [],
      "conceptualFrameworkReference": null,
      "guidingModels": [
        {
          "modelName": "Model Context Protocol (MCP)",
          "relevance": "The MCP standardizes API calls to large language models, data sources, and agentic tools, which is central to the research on security vulnerabilities."
        }
      ],
      "philosophicalParadigm": null,
      "schoolOfThought": null,
      "extractionConfidence": 0.5,
      "paper": "91ca574d82d74528b38e6b88ed227331"
    }
  ],
  "sciknow-25x1-research-problems": [
    {
      "internal_id": "f2e7f6d1ba844fb6b57f90dc28c53547",
      "problemStatement": "The Model Context Protocol (MCP), designed to standardize API calls to large language models (LLMs), data sources, and agentic tools for seamless integration in generative AI applications, carries a wide range of security risks for end-users, including malicious code execution, remote access control, and credential theft.",
      "problemScope": "The scope includes the security vulnerabilities inherent in the MCP's design, which affects the integration and operation of LLMs in generative AI applications.",
      "problemType": "DesignProblem",
      "problemImportance": "Addressing these security risks is crucial to prevent exploitation that could lead to unauthorized system access, data breaches, and other malicious activities.",
      "businessRelevance": "Ensuring the security of generative AI applications is vital for maintaining user trust, protecting intellectual property, and preventing financial losses due to security breaches.",
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331"
    }
  ],
  "sciknow-25x1-knowledge-gaps": [
    {
      "internal_id": "22a8b4832a904832a805a4cd0791ba8f",
      "gapDescription": "The current Model Context Protocol (MCP) design carries a wide range of security risks for end-users, including malicious code execution, remote access control, and credential theft.",
      "relatedDomain": "Cybersecurity in Generative AI",
      "gapSignificance": "Addressing these security risks is crucial to protect AI developers' systems from potential attacks and unauthorized access.",
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    },
    {
      "internal_id": "531cc347a1c349e2b43c44bea76359a0",
      "gapDescription": "Existing Large Language Models (LLMs) such as Claude and Llama-3.3-70B-Instruct, when enabled with MCP servers, are susceptible to various attacks, and their guardrails may not reliably prevent these attacks.",
      "relatedDomain": "AI Safety and Security",
      "gapSignificance": "Improving the reliability of LLM guardrails is necessary to prevent malicious system attacks that can compromise user systems.",
      "extractionConfidence": 0.85,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    },
    {
      "internal_id": "e4eecf92b5ef4821baa0d766b1fee220",
      "gapDescription": "There is a lack of tools for proactive vulnerability detection and remediation in MCP-enabled systems.",
      "relatedDomain": "AI Application Security",
      "gapSignificance": "Developing such tools would allow for the identification and patching of security vulnerabilities before deployment, reducing the risk of zero-day exploits.",
      "extractionConfidence": 0.8,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    },
    {
      "internal_id": "220cebe7aa3347a5bdf0d5190750de41",
      "gapDescription": "The potential for Retrieval-Agent Deception (RADE) attacks in MCP-enabled agentic workflows has not been fully explored or mitigated.",
      "relatedDomain": "AI-Enabled Cybersecurity Threats",
      "gapSignificance": "Understanding and mitigating RADE attacks is important to prevent attackers from corrupting publicly available data and executing malicious commands on user systems.",
      "extractionConfidence": 0.75,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    }
  ],
  "sciknow-25x1-research-questions": [
    {
      "internal_id": "81387df97e7443519f2356fd4006c27f",
      "questionText": "What are the security risks associated with the current Model Context Protocol (MCP) design when used with large language models (LLMs)?",
      "questionType": "Exploratory",
      "relatedVariables": [
        {
          "variableName": "MCP design",
          "variableRole": "Independent"
        },
        {
          "variableName": "Security risks",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547",
      "addressesGap": "22a8b4832a904832a805a4cd0791ba8f"
    },
    {
      "internal_id": "d7f8e16d3a70498cb11c85ed859d96ff",
      "questionText": "Can industry-leading LLMs be coerced to use MCP tools to compromise an AI developer's system, and if so, how?",
      "questionType": "Causal",
      "relatedVariables": [
        {
          "variableName": "LLMs coercion",
          "variableRole": "Independent"
        },
        {
          "variableName": "System compromise",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547",
      "addressesGap": "22a8b4832a904832a805a4cd0791ba8f"
    },
    {
      "internal_id": "ccfa354bf7184c81b1f005572f75aaa1",
      "questionText": "How effective is the McpSafetyScanner tool in assessing the security of an arbitrary MCP server and addressing detected vulnerabilities?",
      "questionType": "Evaluative",
      "relatedVariables": [
        {
          "variableName": "McpSafetyScanner tool effectiveness",
          "variableRole": "Dependent"
        },
        {
          "variableName": "MCP server security assessment",
          "variableRole": "Independent"
        },
        {
          "variableName": "Vulnerability remediation",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547",
      "addressesGap": "22a8b4832a904832a805a4cd0791ba8f"
    },
    {
      "internal_id": "af2c2e08072146c883ad71c151369dd9",
      "questionText": "What types of attacks are enabled through MCP tools, and what are their potential impacts?",
      "questionType": "Descriptive",
      "relatedVariables": [
        {
          "variableName": "Types of attacks",
          "variableRole": "Independent"
        },
        {
          "variableName": "Potential impacts",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547",
      "addressesGap": "22a8b4832a904832a805a4cd0791ba8f"
    },
    {
      "internal_id": "f6c170873f61483a9aae831d244605fd",
      "questionText": "How reliable are the guardrails of LLMs in preventing security attacks when integrated with MCP servers?",
      "questionType": "Evaluative",
      "relatedVariables": [
        {
          "variableName": "LLMs guardrails reliability",
          "variableRole": "Dependent"
        },
        {
          "variableName": "Security attacks prevention",
          "variableRole": "Independent"
        }
      ],
      "extractionConfidence": 0.85,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547",
      "addressesGap": "22a8b4832a904832a805a4cd0791ba8f"
    }
  ],
  "sciknow-25x1-future-directions": [],
  "sciknow-25x1-potential-applications": [],
  "sciknow-25x1-scientific-challenges": [
    {
      "internal_id": "7a22c54a8c734f7a94b24330d301937f",
      "challengeDescription": "The current design of the Model Context Protocol (MCP) carries a wide range of security risks for end-users, such as malicious code execution, remote access control, and credential theft.",
      "challengeType": "ComplexityChallenge",
      "severity": "Major",
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    },
    {
      "internal_id": "131c8344ffea416a9c50257bee77889e",
      "challengeDescription": "The lack of reliable guardrails for potentially malicious attacks within large language models (LLMs) when integrated with MCP tools, leading to varying reliability of these guardrails to prevent attacks.",
      "challengeType": "EmergentBehavior",
      "severity": "Major",
      "extractionConfidence": 0.85,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    },
    {
      "internal_id": "9e2b5cf1552a4a539e2288b04d4749dc",
      "challengeDescription": "The difficulty in proactively mitigating security risks and detecting vulnerabilities in MCP servers due to the complexity and variability of the attacks and the integration of multiple components.",
      "challengeType": "ComplexityChallenge",
      "severity": "Major",
      "extractionConfidence": 0.85,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    },
    {
      "internal_id": "24a626a00867451d830cf460ecb402c1",
      "challengeDescription": "The challenge of ensuring the safety of generative AI workflows, which are susceptible to new types of attacks such as Retrieval-Agent Deception (RADE) attacks, where attackers corrupt publicly available data to execute malicious commands.",
      "challengeType": "EmergentBehavior",
      "severity": "Major",
      "extractionConfidence": 0.8,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "relatedProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    }
  ],
  "sciknow-25x1-methodological-challenges": [],
  "sciknow-25x1-implementation-challenges": [
    {
      "internal_id": "10a7df11448d4675bc83552a51d5642b",
      "challengeDescription": "Security risks for end-users due to the current MCP design, including malicious code execution, remote access control, and credential theft.",
      "resourceConstraint": "Expertise",
      "technicalHurdle": "Need for reliable guardrails for potentially malicious attacks",
      "extractionConfidence": 0.9,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "encounteredInFramework": "8955232b230042fe878642df879c48bd"
    },
    {
      "internal_id": "198a42c4ef6244d290c4888717cf651f",
      "challengeDescription": "Difficulty in ensuring the safety of MCP servers and addressing detected vulnerabilities prior to deployment.",
      "resourceConstraint": "Time",
      "technicalHurdle": "Development of proactive tools like McpSafetyScanner to audit the safety of MCP servers",
      "extractionConfidence": 0.8,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "encounteredInFramework": "8955232b230042fe878642df879c48bd"
    },
    {
      "internal_id": "7c5045dc867840cc961a6edb8e0986cc",
      "challengeDescription": "The threat level increases drastically in shared-office or communal settings, where attackers might have direct access to the MCP user's system.",
      "resourceConstraint": "Infrastructure",
      "technicalHurdle": "Preventing unauthorized access in environments with shared resources",
      "extractionConfidence": 0.7,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "encounteredInFramework": "8955232b230042fe878642df879c48bd"
    },
    {
      "internal_id": "af214677065a4b5aa50d4b75aae13509",
      "challengeDescription": "LLMs require re-evaluation given the immediate safety-and-security implications of enabling LLMs with MCP tools.",
      "resourceConstraint": "Expertise",
      "technicalHurdle": "Conducting comprehensive safety alignment and cybersecurity evaluation for LLMs integrated with MCP tools",
      "extractionConfidence": 0.85,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "encounteredInFramework": "8955232b230042fe878642df879c48bd"
    }
  ],
  "sciknow-25x1-limitations": [],
  "sciknow-25x1-methodological-frameworks": [
    {
      "internal_id": "8955232b230042fe878642df879c48bd",
      "name": "MCP Safety Audit Framework",
      "description": "The study employs a methodological framework designed to assess the security vulnerabilities of the Model Context Protocol (MCP) when integrated with large language models (LLMs). The framework involves simulating attack scenarios, analyzing the responses of LLMs to these attacks, and introducing a safety auditing tool, McpSafetyScanner, to proactively detect and suggest remediations for vulnerabilities.",
      "studyDesign": {
        "designType": "Simulation",
        "controlGroup": false,
        "randomization": false,
        "blinding": null,
        "timeDimension": "CrossSectional",
        "designDetails": "The study simulates various security attack scenarios, such as Malicious code execution (MCE), Remote access control (RAC), and Credential Theft (CT), to evaluate the robustness of MCP's security measures. The study does not involve a control group or randomization, as it is focused on the direct assessment of the protocol's current implementation."
      },
      "procedures": [
        {
          "procedureName": "Security Vulnerability Assessment",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Simulate various security attacks on MCP servers, such as MCE, RAC, and CT, using LLMs like Claude and Llama-3.3-70B-Instruct.",
              "inputs": "Attack commands and scenarios",
              "outputs": "LLM responses and system behavior",
              "parameters": {}
            },
            {
              "stepNumber": 2,
              "description": "Use McpSafetyScanner to automatically probe the system environment and actions enabled by the server for vulnerabilities.",
              "inputs": "MCP server's features",
              "outputs": "Detected vulnerabilities and remediation steps",
              "parameters": {}
            },
            {
              "stepNumber": 3,
              "description": "Generate a detailed security report consolidating all vulnerabilities and remediations.",
              "inputs": "Vulnerabilities and remediation steps",
              "outputs": "Security report",
              "parameters": {}
            }
          ],
          "procedureDescription": "The procedure involves simulating attack scenarios to evaluate the security vulnerabilities of MCP when used with LLMs. It includes the use of the McpSafetyScanner tool to automatically detect vulnerabilities and suggest remediations."
        }
      ],
      "dataAnalysis": {
        "analysisApproach": "QualitativeContentAnalysis",
        "statisticalTests": null,
        "algorithmsUsed": null,
        "softwareDetails": "McpSafetyScanner, Claude for Mac v0.8.1, Agno v1.2.6, gpt-4o-2024-08-0, mcp v1.1.2, huggingface-hub v0.29.3, GNU netcat v0.7.1",
        "parameterSettings": null,
        "dataPreprocessingSteps": null,
        "summary": "The data analysis involves evaluating the responses of LLMs to simulated security attacks, determining the effectiveness of guardrails, and analyzing the output of the McpSafetyScanner tool. The analysis focuses on identifying patterns in the LLMs' behavior, the conditions under which guardrails are triggered, and the comprehensiveness of the McpSafetyScanner's vulnerability detection."
      },
      "resultsRepresentation": {
        "representationFormat": "TextualDescription",
        "visualizationType": null,
        "reportingStandard": null,
        "summary": "The study's findings indicate that both Claude and Llama-3.3-70B-Instruct LLMs are susceptible to MCE, RAC, and CT attacks under certain conditions. The McpSafetyScanner tool successfully identified vulnerabilities and provided remediation steps, demonstrating its effectiveness in enhancing the security of MCP servers."
      },
      "reproducibilityAndSharing": {
        "dataAvailabilityStatement": "The described MCP server auditing tool, McpSafetyScanner, is freely available at the provided GitHub repository.",
        "dataRepository": "https://github.com/johnhalloran321/mcpSafetyScanner",
        "codeAvailabilityStatement": "The code for the McpSafetyScanner tool is available in the GitHub repository.",
        "codeRepository": "https://github.com/johnhalloran321/mcpSafetyScanner",
        "protocolAvailability": null,
        "commercializationPartners": null
      },
      "extractionConfidence": 0.85,
      "paper": "91ca574d82d74528b38e6b88ed227331",
      "researchProblem": "f2e7f6d1ba844fb6b57f90dc28c53547"
    }
  ],
  "sciknow-25x1-material-tools": [
    {
      "internal_id": "590e0aa9507a4ba3aaffb7c1b16ffd23",
      "itemName": "MaterialTool",
      "itemType": null,
      "identifier": null,
      "specifications": null,
      "roleInProcedure": null,
      "extractionConfidence": 0.7,
      "usedInFrameworks": [
        "8955232b230042fe878642df879c48bd"
      ]
    }
  ]
}