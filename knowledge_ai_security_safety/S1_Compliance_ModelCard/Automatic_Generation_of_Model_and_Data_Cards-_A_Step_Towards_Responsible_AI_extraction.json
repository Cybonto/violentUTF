{
  "sciknow-25x1-scientific-papers": [
    {
      "internal_id": "79ee6fe33f874eff9bdf62fab057d205",
      "title": "Automatic generation of model and data cards: A step towards responsible AI",
      "authors": [
        {
          "name": "J Liu"
        },
        {
          "name": "W Li"
        },
        {
          "name": "Z Jin"
        },
        {
          "name": "M Diab"
        }
      ],
      "abstract": "In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-generated model and data cards. We propose an automated generation approach using Large Language Models (LLMs). Our key contributions include the establishment of CARDBENCH, a comprehensive dataset aggregated from over 4.8k model cards and 1.4k data cards, coupled with the development of the CARDGEN pipeline comprising a two-step retrieval process. Our approach exhibits enhanced completeness, objectivity, and faithfulness in generated model and data cards, a significant step in responsible AI documentation practices ensuring better accountability and traceability. 1",
      "doi": "",
      "publicationDate": "2024",
      "journal": "arXiv preprint arXiv:2405.06258, 2024",
      "volume": "4",
      "issue": "",
      "pages": "",
      "keywords": [],
      "pdfPath": "/Users/tamnguyen/Documents/AI-Safety_Privacy/S1_Compliance_ModelCard/Automatic Generation of Model and Data Cards- A Step Towards Responsible AI.pdf",
      "fileUrl": "https://arxiv.org/abs/2405.06258",
      "extractionDate": "2025-04-29T07:34:31.752393",
      "extractionConfidenceScore": 0.8182
    }
  ],
  "sciknow-25x1-research-contexts": [
    {
      "internal_id": "c58d145b64cc492fa34275356ca81b9c",
      "discipline": "Computer Science",
      "fieldOfStudy": "Artificial Intelligence, Machine Learning, Responsible AI",
      "associatedProject": null,
      "fundingSources": [],
      "institutions": [
        {
          "name": "Carnegie Mellon University",
          "location": null
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205"
    }
  ],
  "sciknow-25x1-theoretical-bases": [
    {
      "internal_id": "b2de015666c0484189b7c6eb1147e990",
      "underlyingTheories": [],
      "conceptualFrameworkReference": null,
      "guidingModels": [
        {
          "modelName": "Model cards by Mitchell et al. (2019)",
          "relevance": "The concept of model cards is used as a foundation for developing a standardized approach to AI documentation."
        },
        {
          "modelName": "Data cards by Pushkarna et al. (2022)",
          "relevance": "The concept of data cards is used as a foundation for developing a standardized approach to AI documentation."
        }
      ],
      "philosophicalParadigm": "Not Specified",
      "schoolOfThought": null,
      "extractionConfidence": 0.6,
      "paper": "79ee6fe33f874eff9bdf62fab057d205"
    }
  ],
  "sciknow-25x1-research-problems": [
    {
      "internal_id": "9bc7a2a4c3624584b0625080b5cfa955",
      "problemStatement": "The research addresses the problem of information incompleteness in current human-generated model and data cards, which are critical for communicating the performance characteristics of AI models and datasets.",
      "problemScope": "The scope includes the standardization and consistency of AI documentation practices, specifically focusing on model and data cards.",
      "problemType": "DesignProblem",
      "problemImportance": "Standardized documentation is crucial for ensuring accountability and traceability in AI, which affects the reliability and development of AI technologies.",
      "businessRelevance": "Improving AI documentation practices can lead to better development processes, reduced error propagation, and enhanced accountability in AI applications, which is vital for industry stakeholders.",
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205"
    }
  ],
  "sciknow-25x1-knowledge-gaps": [
    {
      "internal_id": "087ef44b19654a9890e1135d5b283772",
      "gapDescription": "The potential for hallucinations in the generated text of model cards and data cards due to the adoption of the RAG pipeline and explicit instructions for LLMs.",
      "relatedDomain": "Natural Language Processing",
      "gapSignificance": "Reducing hallucinations is crucial for ensuring the accuracy and reliability of automatically generated documentation in AI.",
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "8b141e7f9b304fbebe247aa3a1f8e98c",
      "gapDescription": "The need for advanced chain-of-thought prompting techniques and iterative retrieval-generation collaborative frameworks to handle complex questions requiring multistep reasoning.",
      "relatedDomain": "Natural Language Processing",
      "gapSignificance": "Improving the ability of LLMs to handle complex reasoning tasks is essential for generating more accurate and comprehensive AI documentation.",
      "extractionConfidence": 0.75,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "c4cbc2d134c748a7a30d64ae197c2cf3",
      "gapDescription": "The risk of receiving biased responses from LLMs, particularly for queries about model limitations, due to biased source papers and GitHub READMEs.",
      "relatedDomain": "Ethics in AI",
      "gapSignificance": "Addressing biases in LLM responses is important for creating fair and unbiased AI documentation, which is critical for responsible AI development.",
      "extractionConfidence": 0.7,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "e77d18c34d0f4f2188b964bc4ba9313d",
      "gapDescription": "The potential for content homogeneity when using LLMs for model card generation, which could limit the discussion of new issues not covered in original papers or repositories.",
      "relatedDomain": "AI Documentation",
      "gapSignificance": "Ensuring diversity in AI documentation is important for capturing a wide range of issues and perspectives, which can lead to more responsible AI development.",
      "extractionConfidence": 0.7,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "5684b15f7b154bcf824efef0fe9ebdb4",
      "gapDescription": "The lack of a fine-tuning process on human-generated model cards, which could lead to biases from the internal workings of LLMs, such as overstatements or omissions of potential risks.",
      "relatedDomain": "Machine Learning",
      "gapSignificance": "Fine-tuning LLMs on high-quality human-generated model cards can improve the performance of automatic documentation generation and reduce biases.",
      "extractionConfidence": 0.7,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    }
  ],
  "sciknow-25x1-research-questions": [
    {
      "internal_id": "f5da434d43414325a06e8609b9672614",
      "questionText": "How can Large Language Models (LLMs) be systematically utilized for automatically generating model/data cards?",
      "questionType": "Methodological",
      "relatedVariables": [
        {
          "variableName": "Large Language Models",
          "variableRole": "Independent"
        },
        {
          "variableName": "Model/Data cards generation",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    },
    {
      "internal_id": "b482c96ff8924bc08f02dbc717ef4d27",
      "questionText": "Does the CARDGEN pipeline improve the completeness, objectivity, and faithfulness in generated model and data cards compared to human-generated cards?",
      "questionType": "Comparative",
      "relatedVariables": [
        {
          "variableName": "CARDGEN pipeline",
          "variableRole": "Independent"
        },
        {
          "variableName": "Completeness, objectivity, and faithfulness of documentation",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    },
    {
      "internal_id": "5b4e0af966734649ad42066ef8774fc2",
      "questionText": "What are the potential biases in responses from LLMs when generating model cards, and how can they be mitigated?",
      "questionType": "Evaluative",
      "relatedVariables": [
        {
          "variableName": "LLM-generated model cards",
          "variableRole": "Independent"
        },
        {
          "variableName": "Potential biases",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.85,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    },
    {
      "internal_id": "58f8b903737c4a1fbab12ea41197c856",
      "questionText": "Can advanced chain-of-thought prompting techniques improve the CARDGEN pipeline for complex questions requiring multistep reasoning?",
      "questionType": "Exploratory",
      "relatedVariables": [
        {
          "variableName": "Chain-of-thought prompting techniques",
          "variableRole": "Independent"
        },
        {
          "variableName": "CARDGEN pipeline effectiveness",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    },
    {
      "internal_id": "217da21375864a849a89345ddfd77383",
      "questionText": "How does the iterative retrieval-generation collaborative framework refine responses in the CARDGEN pipeline based on newly retrieved contexts?",
      "questionType": "Methodological",
      "relatedVariables": [
        {
          "variableName": "Iterative retrieval-generation collaborative framework",
          "variableRole": "Independent"
        },
        {
          "variableName": "Refinement of responses",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    }
  ],
  "sciknow-25x1-future-directions": [
    {
      "internal_id": "e347f64fc25c4d7f8b57c1e55917ea86",
      "directionDescription": "Integrate specific strategies into the CARDGEN pipeline for hallucination reduction by carefully balancing generation speed with quality.",
      "timeframe": "Not specified",
      "requiredResources": null,
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    },
    {
      "internal_id": "223be0ba0deb4e36888115fee0baa4cb",
      "directionDescription": "Incorporate more advanced chain-of-thought prompting techniques and compare with the CARDGEN pipeline.",
      "timeframe": "Not specified",
      "requiredResources": null,
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    },
    {
      "internal_id": "8d298b9866284f709b8401aa5a45a77c",
      "directionDescription": "Employ an iterative retrieval-generation collaborative framework to refine responses in each iteration based on newly retrieved contexts.",
      "timeframe": "Not specified",
      "requiredResources": null,
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "addressesGap": "087ef44b19654a9890e1135d5b283772"
    }
  ],
  "sciknow-25x1-potential-applications": [],
  "sciknow-25x1-scientific-challenges": [
    {
      "internal_id": "910a41ad7b234dc3a4ea2fbf0f557cee",
      "challengeDescription": "The potential for hallucinations in the generated text by LLMs, which can lead to inaccuracies in the documentation.",
      "challengeType": "Other",
      "severity": "Moderate",
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "0973234842194f629b5ff28c542f9f36",
      "challengeDescription": "The risk of receiving biased responses from LLMs, particularly for certain queries that may contain overstated claims in the source papers and GitHub READMEs.",
      "challengeType": "Other",
      "severity": "Moderate",
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "e3c40c2e8eda45c4a0aad8d955c97922",
      "challengeDescription": "Content homogeneity when using LLMs for model card generation, which could limit the potential to discuss new issues not covered in the original papers or GitHub repositories.",
      "challengeType": "Other",
      "severity": "Moderate",
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    },
    {
      "internal_id": "379fd61ff4da4c489a6432c1ac5eea37",
      "challengeDescription": "Biases from the internal workings of LLMs, such as overstatements on well-known models or omissions of potential risks.",
      "challengeType": "Other",
      "severity": "Moderate",
      "extractionConfidence": 0.8,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "relatedProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    }
  ],
  "sciknow-25x1-methodological-challenges": [],
  "sciknow-25x1-implementation-challenges": [],
  "sciknow-25x1-limitations": [],
  "sciknow-25x1-methodological-frameworks": [
    {
      "internal_id": "ab34f22b5afa44308d2157ae9020fec4",
      "name": "Automatic generation of model and data cards using Large Language Models",
      "description": "The study presents a methodological framework for the automated generation of model and data cards, which are essential tools for documenting machine learning models and datasets. The framework leverages Large Language Models (LLMs) to enhance the completeness, objectivity, and faithfulness of the generated documentation. The approach involves a comprehensive dataset (CARDBENCH) and a novel pipeline (CARDGEN) that includes a two-step retrieval process for generating model and data cards.",
      "variables": [],
      "procedures": [
        {
          "procedureName": "CARDGEN Pipeline",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Split questions into sub-questions using LLMs.",
              "inputs": "Question template set",
              "outputs": "Sub-question set",
              "parameters": {}
            },
            {
              "stepNumber": 2,
              "description": "Infer relevant sections as potential knowledge sources from the model's paper and README documents.",
              "inputs": "Sub-question set",
              "outputs": "Inferred relevant sections",
              "parameters": {}
            },
            {
              "stepNumber": 3,
              "description": "Generate pseudo answers leveraging LLM's own knowledge.",
              "inputs": "Sub-question set",
              "outputs": "Pseudo answers",
              "parameters": {}
            },
            {
              "stepNumber": 4,
              "description": "Retrieve relevant document chunks using the pseudo answer as a query.",
              "inputs": "Pseudo answers",
              "outputs": "Set of relevant document chunks",
              "parameters": {}
            },
            {
              "stepNumber": 5,
              "description": "Generate final answers for the questions prepended with highest-ranked document chunks.",
              "inputs": "Set of relevant document chunks and questions",
              "outputs": "Generated answers for all questions",
              "parameters": {}
            }
          ],
          "procedureDescription": "The CARDGEN pipeline is a structured approach that decomposes the card generation task into multiple sub-tasks, including a two-step retrieval process. It involves prompting LLMs to split questions into sub-questions, inferring relevant sections as potential knowledge sources, generating pseudo answers, and retrieving relevant document chunks to generate answers for the questions."
        }
      ],
      "dataAnalysis": {
        "analysisApproach": "Quantitative and qualitative evaluation",
        "statisticalTests": null,
        "algorithmsUsed": "Large Language Models (LLMs)",
        "softwareDetails": "GPT-3.5, GPT-4, Claude 3 Opus, Llama2 70B Chat, Vicuna 13B V1.5, Mistral 7B Instruct",
        "parameterSettings": null,
        "dataPreprocessingSteps": null,
        "summary": "The study evaluates the CARDGEN pipeline using both traditional metrics and LLM-based automatic metrics, as well as detailed human evaluation. The evaluation focuses on multiple performance aspects, including faithfulness, relevance, and other aspects of generation quality."
      },
      "reproducibilityAndSharing": {
        "dataAvailabilityStatement": "The code and data are available on GitHub.",
        "dataRepository": "https://github.com/jiarui-liu/AutomatedModelCardGeneration",
        "codeAvailabilityStatement": "The code is available on GitHub.",
        "codeRepository": "https://github.com/jiarui-liu/AutomatedModelCardGeneration",
        "protocolAvailability": null,
        "commercializationPartners": null
      },
      "extractionConfidence": 0.9,
      "paper": "79ee6fe33f874eff9bdf62fab057d205",
      "researchProblem": "9bc7a2a4c3624584b0625080b5cfa955"
    }
  ],
  "sciknow-25x1-material-tools": [
    {
      "internal_id": "1f09cb4ad13e46238b1de1dce0247f01",
      "itemName": "Hammer",
      "itemType": "Tool",
      "identifier": "HMR-001",
      "specifications": "Steel head, wooden handle, 16oz",
      "roleInProcedure": "Used for driving nails into wood",
      "extractionConfidence": 0.9,
      "usedInFrameworks": [
        "ab34f22b5afa44308d2157ae9020fec4"
      ]
    }
  ]
}