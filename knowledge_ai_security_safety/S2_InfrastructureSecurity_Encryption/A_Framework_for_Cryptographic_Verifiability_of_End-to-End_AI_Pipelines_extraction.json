{
  "sciknow-25x1-scientific-papers": [
    {
      "internal_id": "be3de2e7c71d4988a1ba44a9537fe76e",
      "title": "A Framework for Cryptographic Verifiability of End-to-End AI Pipelines",
      "authors": [
        {
          "name": "K Balan"
        },
        {
          "name": "R Learney"
        },
        {
          "name": "T Wood"
        }
      ],
      "abstract": "## Keywords\n\nThe increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently 'linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.\n\n## CCS Concepts\n\n- · Social and professional topics → Technology audits ; · Computing methodologies → Multi-agent systems ; Artificial intelligence ; · Theory of computation → Data provenance ; · Security and privacy → Social aspects of security and privacy ; Cryptography .\n\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\nIWSPA '25, June 6, 2025, Pittsburgh, PA, USA\n\nACM ISBN 978-1-4503-XXXX-X/18/06\n\n© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n\nhttps://doi.org/XXXXXXX.XXXXXXX\n\nZero-Knowledge Proofs, Verifiability, Artificial Intelligence, Machine Unlearning, Data Provenance, AI Compliance\n\n## ACMReference Format:\n\nKar Balan, Robert Learney, and Tim Wood. 2018. A Framework for Cryptographic Verifiability of End-to-End AI Pipelines. In Proceedings of 11th ACM International Workshop on Security and Privacy Analytics (IWSPA '25). ACM, New York, NY, USA, 12 pages. https://doi.org/XXXXXXX.XXXXXXX",
      "doi": "",
      "publicationDate": "2025",
      "journal": "arXiv preprint arXiv:2503.22573, 2025",
      "volume": "1",
      "issue": "",
      "pages": "",
      "keywords": [],
      "pdfPath": "/Users/tamnguyen/Documents/GitHub/SKEO/SKEO_extractor/AI-Safety_Privacy/S2_InfrastructureSecurity_Encryption/A Framework for Cryptographic Verifiability of End-to-End AI Pipelines.pdf",
      "fileUrl": "https://arxiv.org/abs/2503.22573",
      "extractionDate": "2025-04-24T08:17:26.629426",
      "extractionConfidenceScore": 0.8138
    }
  ],
  "sciknow-25x1-research-contexts": [
    {
      "internal_id": "d28a1a29e2be45619329d42e06e1ee4d",
      "discipline": "Computer Science",
      "fieldOfStudy": "Cryptography, Artificial Intelligence",
      "associatedProject": null,
      "fundingSources": [
        {
          "funderName": "UKRI",
          "grantNumber": "EP/T022485/1"
        }
      ],
      "institutions": [
        {
          "name": "Digital Catapult",
          "location": null
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e"
    }
  ],
  "sciknow-25x1-theoretical-bases": [
    {
      "internal_id": "c2f096d9fcc34319b3f6b1788850afa9",
      "underlyingTheories": [],
      "conceptualFrameworkReference": null,
      "guidingModels": [
        {
          "modelName": "C2PA framework",
          "relevance": "Used to provide assurance of media provenance with digital signatures and cryptographic commitments."
        },
        {
          "modelName": "Federated Learning",
          "relevance": "Allows models to be trained without individual entities revealing their data to a third party."
        },
        {
          "modelName": "Zero-Knowledge Proofs",
          "relevance": "Allow proving various model properties, including correctness of model training, data provenance and integrity, or execution of model inference, to third parties without revealing sensitive inputs."
        }
      ],
      "philosophicalParadigm": null,
      "schoolOfThought": "Cryptography and AI Safety",
      "extractionConfidence": 0.6,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e"
    }
  ],
  "sciknow-25x1-research-problems": [
    {
      "internal_id": "e4cc714a5c34472dbedd0ad1f8330e32",
      "problemStatement": "The core research problem addressed in the paper is the lack of robust mechanisms and frameworks for ensuring end-to-end cryptographic verifiability of AI pipelines, which is crucial for transparency, trust, and auditability in the development and deployment of AI systems across various industry sectors.",
      "problemScope": "The problem scope includes the entire AI lifecycle, from data sourcing to training, inference, and unlearning, and the need for cryptographic tools that are efficiently linkable across these processes.",
      "problemType": "DesignProblem",
      "problemImportance": "This problem is critical as it pertains to the increasing integration of AI in critical decision-making processes and the evolving regulatory initiatives demanding transparency and auditability of AI systems.",
      "businessRelevance": "Solving this problem has significant implications for businesses and industries that rely on AI technologies, as it would enable trustless audits and verifiability without compromising privacy, thus aligning AI innovation with market and regulatory demands for safety and compliance.",
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e"
    }
  ],
  "sciknow-25x1-knowledge-gaps": [
    {
      "internal_id": "37079a2aeca54be6b139586a7545490e",
      "gapDescription": "There are no implementations of a fully verifiable end-to-end AI pipeline, although work towards this goal has begun.",
      "relatedDomain": "Cryptographic AI Verifiability",
      "gapSignificance": "A fully verifiable AI pipeline would enable end users to cryptographically verify the entire process from data sourcing to model inference, enhancing trust and compliance in AI systems.",
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "8b86e503c66a4c578d30aee1ff22b943",
      "gapDescription": "Current cryptographic tools and techniques are not efficiently 'linkable' across different processes within the AI pipeline.",
      "relatedDomain": "Cryptographic AI Verifiability",
      "gapSignificance": "Efficiently linking cryptographic tools across AI processes is crucial for developing end-to-end verifiable AI technologies.",
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "f63520623fe2417c9ec98032951fa1cc",
      "gapDescription": "Existing solutions fail to provide full verifiability during the data extraction and analysis phase of the AI pipeline.",
      "relatedDomain": "Data Provenance and AI Pipeline Verifiability",
      "gapSignificance": "Ensuring verifiability during data extraction and analysis is essential for the integrity and trustworthiness of AI systems.",
      "extractionConfidence": 0.85,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "84d1eea2f0734e1ba782981b4796d745",
      "gapDescription": "There is a lack of standard approaches for implementing Zero-Knowledge Proofs (ZKPs) in AI, which hinders interoperability of implementations.",
      "relatedDomain": "Standardization of Cryptographic Protocols in AI",
      "gapSignificance": "Developing standards for ZKPs in AI is necessary to enable interoperability and widespread adoption of cryptographic verifiability in AI systems.",
      "extractionConfidence": 0.75,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "8f839ebf5c2546a09bb2ae683f232a0d",
      "gapDescription": "There is a need for frameworks like DECORAIT to provide immutable metadata records that bind AI model outputs to the models used to generate them.",
      "relatedDomain": "AI Metadata and Provenance",
      "gapSignificance": "Immutable metadata records are crucial for maintaining the integrity of AI model outputs and their provenance, especially when metadata can be maliciously removed or corrupted.",
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "b384d6e147ad4aa59a973dfaf563d1e3",
      "gapDescription": "There is a lack of comprehensive guarantees of model correctness, as ZKPoTs do not prevent all opportunities for biases in models.",
      "relatedDomain": "AI Model Fairness and Correctness",
      "gapSignificance": "Ensuring model correctness and mitigating biases are essential for the ethical deployment of AI systems, and current ZKPoTs do not fully address this issue.",
      "extractionConfidence": 0.7,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    }
  ],
  "sciknow-25x1-research-questions": [
    {
      "internal_id": "4c922908ee3f4f3b99dde7240daa58dd",
      "questionText": "How can cryptographic tools be integrated across different stages of the AI lifecycle to ensure verifiability from data sourcing to training, inference, and unlearning?",
      "questionType": "Exploratory",
      "relatedVariables": [
        {
          "variableName": "Cryptographic tools",
          "variableRole": "Independent"
        },
        {
          "variableName": "AI lifecycle stages",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32",
      "addressesGap": "37079a2aeca54be6b139586a7545490e"
    },
    {
      "internal_id": "e724e2dfd90d417bbc36a1e0e6d9707e",
      "questionText": "What are the existing cryptographic approaches that contribute to verifiability in AI pipelines, and how can they be efficiently linked across different processes within the pipeline?",
      "questionType": "Descriptive",
      "relatedVariables": [
        {
          "variableName": "Cryptographic approaches",
          "variableRole": "Independent"
        },
        {
          "variableName": "Efficiency of linkage",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.85,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32",
      "addressesGap": "37079a2aeca54be6b139586a7545490e"
    },
    {
      "internal_id": "c8069f5d2c1c47b7a7802c1c742b5906",
      "questionText": "What are the gaps and challenges in achieving full end-to-end verifiability within the AI pipeline, and how can they be addressed?",
      "questionType": "Evaluative",
      "relatedVariables": [
        {
          "variableName": "Gaps in AI pipeline verifiability",
          "variableRole": "Independent"
        },
        {
          "variableName": "Challenges in AI pipeline verifiability",
          "variableRole": "Independent"
        }
      ],
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32",
      "addressesGap": "37079a2aeca54be6b139586a7545490e"
    },
    {
      "internal_id": "a8dd5114a415499fa2e75e1593a148fc",
      "questionText": "How can a framework for end-to-end verifiable AI pipelines be developed to align AI innovation with public interest and legal safeguards?",
      "questionType": "Applied",
      "relatedVariables": [
        {
          "variableName": "Framework for AI pipelines",
          "variableRole": "Independent"
        },
        {
          "variableName": "Alignment with public interest",
          "variableRole": "Dependent"
        },
        {
          "variableName": "Legal safeguards",
          "variableRole": "Dependent"
        }
      ],
      "extractionConfidence": 0.85,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32",
      "addressesGap": "37079a2aeca54be6b139586a7545490e"
    }
  ],
  "sciknow-25x1-future-directions": [
    {
      "internal_id": "7dba17a293b04b159f23c4a28f7d15c7",
      "directionDescription": "Developing ZKP standards for AI verifiability and interoperability of implementations.",
      "timeframe": "Medium-term",
      "requiredResources": null,
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "addressesGap": "37079a2aeca54be6b139586a7545490e",
      "extendsPotentialApplication": "6ad612ac259b46cf9a86a8434cfa8bd8"
    },
    {
      "internal_id": "f01876296971486f846b49d92950ecf7",
      "directionDescription": "Research on gaps in the verifiability of the AI pipeline for full end-to-end verifiability.",
      "timeframe": "Long-term",
      "requiredResources": null,
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "addressesGap": "37079a2aeca54be6b139586a7545490e",
      "extendsPotentialApplication": "6ad612ac259b46cf9a86a8434cfa8bd8"
    },
    {
      "internal_id": "54b928b304464eba8b873948c1e6d1b0",
      "directionDescription": "Regulators verifying ZKPs to enhance trust in AI systems while maintaining privacy of proprietary models.",
      "timeframe": "Medium-term",
      "requiredResources": null,
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "addressesGap": "37079a2aeca54be6b139586a7545490e",
      "extendsPotentialApplication": "6ad612ac259b46cf9a86a8434cfa8bd8"
    }
  ],
  "sciknow-25x1-potential-applications": [
    {
      "internal_id": "6ad612ac259b46cf9a86a8434cfa8bd8",
      "applicationDescription": "Combatting misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness.",
      "targetSector": "Technology",
      "implementationReadiness": "Proof of Concept",
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "buildOnMethodologicalFrameworks": [
        "c7e6e45763364eddba8d4d409db26610"
      ]
    },
    {
      "internal_id": "691d5986c22b4303bd88efbad5649a5c",
      "applicationDescription": "Supporting regulatory compliance by enabling real-world demonstration of compliance with AI safety regulations through the use of Zero-Knowledge Proofs (ZKPs).",
      "targetSector": "Government",
      "implementationReadiness": "Conceptual",
      "extractionConfidence": 0.7,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "buildOnMethodologicalFrameworks": [
        "c7e6e45763364eddba8d4d409db26610"
      ]
    },
    {
      "internal_id": "a8a748157a4c458aa96a8e3f42e87b12",
      "applicationDescription": "Enhancing trust in AI systems by allowing regulators to verify ZKPs of proprietary models on behalf of users, maintaining model privacy while providing security guarantees.",
      "targetSector": "Multiple",
      "implementationReadiness": "Conceptual",
      "extractionConfidence": 0.7,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "buildOnMethodologicalFrameworks": [
        "c7e6e45763364eddba8d4d409db26610"
      ]
    }
  ],
  "sciknow-25x1-scientific-challenges": [
    {
      "internal_id": "e0a5f97aac8c46f683a7460d6593a3f0",
      "challengeDescription": "Achieving end-to-end verifiability in AI pipelines due to the high computational complexity of AI training and inference.",
      "challengeType": "ComplexityChallenge",
      "severity": "Major",
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "fc5ebfd573ad4b0da3fbb4f27b06d17d",
      "challengeDescription": "Developing cryptographic tools that are efficiently 'linkable' across different processes within the AI pipeline.",
      "challengeType": "TheoryGap",
      "severity": "Moderate",
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "b870e2ad07194b79bdef1c41e9fc9e62",
      "challengeDescription": "Standardisation of Zero-Knowledge Proofs (ZKPs) due to the continual improvements through research efforts, providing a moving target that makes standardisation challenging.",
      "challengeType": "ScaleChallenge",
      "severity": "Moderate",
      "extractionConfidence": 0.7,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "aaa50883a05b4d34afc963b28b215d0b",
      "challengeDescription": "Ensuring verifiable data provenance in the context of AI training to prevent training AI systems on manipulated, biased, erroneous, or copyrighted data without creator consent.",
      "challengeType": "ComplexityChallenge",
      "severity": "Major",
      "extractionConfidence": 0.85,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "2c45e8b179a54c94b68fe2cd612eb27d",
      "challengeDescription": "Applying Zero-Knowledge Proofs to large-scale neural network training, which has been traditionally considered computationally prohibitive.",
      "challengeType": "ScaleChallenge",
      "severity": "Major",
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "f9b66da25174479fb77da6df3e7bf1a1",
      "challengeDescription": "Generalisability and efficiency challenges in ZKP systems due to the complexity and scale of modern ML models and the inherently computationally expensive nature of machine learning tasks.",
      "challengeType": "ScaleChallenge",
      "severity": "Major",
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "fa6bf47363154dd5967530bd31b478ff",
      "challengeDescription": "Maintaining model architecture confidentiality while representing it as the ZKP circuit itself, which is necessary for generating Zero-Knowledge Proofs of Training.",
      "challengeType": "PrivacyChallenge",
      "severity": "Moderate",
      "extractionConfidence": 0.75,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    },
    {
      "internal_id": "8dda83b997354a378ba309435dea00b8",
      "challengeDescription": "Ensuring the integrity and correctness of the training process while maintaining data and model privacy in regulatory contexts such as the EU AI Act.",
      "challengeType": "PrivacyChallenge",
      "severity": "Moderate",
      "extractionConfidence": 0.8,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "relatedProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    }
  ],
  "sciknow-25x1-methodological-challenges": [],
  "sciknow-25x1-implementation-challenges": [],
  "sciknow-25x1-limitations": [],
  "sciknow-25x1-methodological-frameworks": [
    {
      "internal_id": "c7e6e45763364eddba8d4d409db26610",
      "name": "A Framework for Cryptographic Verifiability of End-to-End AI Pipelines",
      "description": "The proposed framework aims to achieve end-to-end cryptographic verifiability in AI pipelines by ensuring that each process in the pipeline is executed honestly and that the inputs to each process are indeed the outputs of the previous process. The framework encompasses the entire AI lifecycle, from data sourcing to training, inference, and unlearning, and utilizes cryptographic tools such as digital signatures, cryptographic commitments, and Zero-Knowledge Proofs (ZKPs) to provide verifiability.",
      "studyDesign": {
        "designType": "Other",
        "controlGroup": false,
        "randomization": false,
        "blinding": null,
        "timeDimension": "NotSpecified",
        "designDetails": "The study is not experimental but proposes a theoretical framework for cryptographic verifiability. It does not involve control groups, randomization, or blinding as it is not testing hypotheses but rather outlining a structured approach to ensure transparency and trust in AI systems."
      },
      "variables": [],
      "procedures": [
        {
          "procedureName": "End-to-End Verifiable AI Pipeline",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Verification of raw dataset using digital signatures and Zero-Knowledge Proofs of Fairness (ZKPoFs) to ensure authenticity and assess properties like dataset bias.",
              "inputs": "Raw dataset",
              "outputs": "Verified dataset",
              "parameters": {}
            },
            {
              "stepNumber": 2,
              "description": "Extraction and analysis of data to prepare the final training dataset, applying transformations such as normalization.",
              "inputs": "Verified dataset",
              "outputs": "Final training dataset",
              "parameters": {}
            },
            {
              "stepNumber": 3,
              "description": "Model training using the training dataset with cryptographic proofs to verify the training process.",
              "inputs": "Final training dataset",
              "outputs": "Trained model",
              "parameters": {}
            },
            {
              "stepNumber": 4,
              "description": "Model evaluation to assess whether the model meets design requirements using proofs for private aggregation of performance metrics.",
              "inputs": "Trained model",
              "outputs": "Evaluation results",
              "parameters": {}
            },
            {
              "stepNumber": 5,
              "description": "Model inference to deploy and serve the model, using Zero-Knowledge Proofs of Inference (ZKPoIs) for verification.",
              "inputs": "Trained model",
              "outputs": "Inference results",
              "parameters": {}
            },
            {
              "stepNumber": 6,
              "description": "Machine unlearning to verify the removal of specific data points from the model using Zero-Knowledge Proofs of Unlearning (ZKPoUs).",
              "inputs": "Trained model",
              "outputs": "Updated model",
              "parameters": {}
            }
          ],
          "procedureDescription": "The procedure involves the application of cryptographic tools to verify the authenticity and integrity of each stage in the AI pipeline, including data sourcing, model training, inference, and unlearning. The framework outlines the use of digital signatures for data provenance, federated learning for privacy-preserving model training, and various forms of ZKPs to prove properties such as model training correctness and inference accuracy without revealing sensitive information."
        }
      ],
      "validationAndVerification": {
        "validationTypes": [],
        "validationProcedure": null,
        "validationMetrics": null,
        "validationResults": null,
        "industryStandards": "C2PA"
      },
      "reproducibilityAndSharing": {
        "dataAvailabilityStatement": "Not specified",
        "dataRepository": null,
        "codeAvailabilityStatement": "Not specified",
        "codeRepository": null,
        "protocolAvailability": "Not specified",
        "commercializationPartners": null
      },
      "extractionConfidence": 0.9,
      "paper": "be3de2e7c71d4988a1ba44a9537fe76e",
      "materialsAndTools": [
        "Decentralised identifiers (DIDs)",
        "Blockchain-based smart contracts"
      ],
      "researchProblem": "e4cc714a5c34472dbedd0ad1f8330e32"
    }
  ],
  "sciknow-25x1-material-tools": [
    {
      "internal_id": "0ab3a41762f64cabbd1ff9bd6bea44cb",
      "itemName": "Hammer",
      "itemType": "Tool",
      "identifier": "HMR-001",
      "specifications": "Steel head, wooden handle, 16oz",
      "roleInProcedure": "Used for driving nails into wood",
      "extractionConfidence": 0.9,
      "usedInFrameworks": [
        "c7e6e45763364eddba8d4d409db26610"
      ]
    }
  ]
}