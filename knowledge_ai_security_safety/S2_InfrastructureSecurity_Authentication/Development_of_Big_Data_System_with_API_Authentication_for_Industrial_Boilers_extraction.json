{
  "sciknow-25x1-scientific-papers": [
    {
      "internal_id": "d258db032e914e31a485fa23cbd58453",
      "title": "Development of Big Data System with API Authentication for Industrial Boilers",
      "authors": [
        {
          "name": "Y Joo"
        },
        {
          "name": "S Park"
        },
        {
          "name": "H Woo"
        },
        {
          "name": "K Kwon"
        }
      ],
      "abstract": "Recent advancements in AI are being recognized as  a  promising  solution  to  improve  the  efficiency  of  industrial boilers. However, high-performance AI models require extensive amounts of training data. To address this, this paper proposes a big data system designed for efficient data collection, processing, storage,  and  sharing.  It  enables  fast  data  storage  and  sharing through  distributed  data  processing,  while  protecting  sensitive data via authentication. Additionally, it provides a data sharing interface that minimizes unnecessary data transfers and reduces delays in additional authentication procedures through caching. Performance evaluation has confirmed that the proposed system delivers  high  throughput  for  write  operations  and  reasonable latency for read operations, even under massive user requests.",
      "doi": "",
      "publicationDate": "2024",
      "journal": "2024 15th International â€¦, 2024",
      "volume": "2",
      "issue": "",
      "pages": "",
      "keywords": [],
      "pdfPath": "/Users/tamnguyen/Documents/AI-Safety_Privacy/S2_InfrastructureSecurity_Authentication/Development_of_Big_Data_System_with_API_Authentication_for_Industrial_Boilers.pdf",
      "fileUrl": "https://ieeexplore.ieee.org/abstract/document/10827348/",
      "extractionDate": "2025-04-28T23:07:22.939507",
      "extractionConfidenceScore": 0.8333
    }
  ],
  "sciknow-25x1-research-contexts": [
    {
      "internal_id": "4c1db95c918b49648b2adc9d41054b0a",
      "discipline": "Computer Science",
      "fieldOfStudy": "Big Data Systems",
      "associatedProject": null,
      "fundingSources": [
        {
          "funderName": "Korea Institute of Energy Technology Evaluation and Planning",
          "grantNumber": "20222020900040"
        },
        {
          "funderName": "Ministry of Trade, Industry & Energy of the Republic of Korea",
          "grantNumber": "20222020900040"
        }
      ],
      "institutions": [],
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453"
    }
  ],
  "sciknow-25x1-theoretical-bases": [
    {
      "internal_id": "3b23b5d7773c4d73a5ab17b118b3e3e1",
      "underlyingTheories": [],
      "conceptualFrameworkReference": null,
      "guidingModels": [],
      "philosophicalParadigm": null,
      "schoolOfThought": null,
      "extractionConfidence": 0.5,
      "paper": "d258db032e914e31a485fa23cbd58453"
    }
  ],
  "sciknow-25x1-research-problems": [
    {
      "internal_id": "e0c94ac9704f4f2baaa3012bddb5c8ba",
      "problemStatement": "The need to develop a Big Data system capable of efficient data collection, processing, storage, and sharing for training AI models to improve the efficiency of industrial boilers.",
      "problemScope": "The scope includes data management for AI model training in the context of industrial boilers, focusing on real-time data processing, secure data collection, and sharing.",
      "problemType": "DesignProblem",
      "problemImportance": "Improving the efficiency of industrial boilers can significantly reduce CO2 and greenhouse gas emissions, as well as lower energy costs.",
      "businessRelevance": "Enhancing industrial boiler efficiency has direct implications for energy cost savings and environmental impact, which are critical concerns for the industry.",
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453"
    }
  ],
  "sciknow-25x1-knowledge-gaps": [
    {
      "internal_id": "8059d7247d7a440b89c01a5693794f0e",
      "gapDescription": "Lack of a Big Data system capable of storing vast amounts of data and enabling authorized users to share data for training AI models in industrial boilers.",
      "relatedDomain": "Industrial Boilers Efficiency & AI Integration",
      "gapSignificance": "Increasing the efficiency of energy use in industrial boilers can reduce CO2 and greenhouse gas emissions, as well as lower energy costs.",
      "extractionConfidence": 0.8,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba"
    },
    {
      "internal_id": "3b88710dacf9434c8d05d89e7b08ff4b",
      "gapDescription": "Limitations in adapting to complex environmental changes and various operating conditions in real-time with the current manual operation of industrial boilers.",
      "relatedDomain": "Industrial Boilers Operational Efficiency",
      "gapSignificance": "Improving real-time adaptability of industrial boilers can enhance performance and efficiency, potentially reducing environmental impact.",
      "extractionConfidence": 0.8,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba"
    }
  ],
  "sciknow-25x1-research-questions": [
    {
      "internal_id": "d2ac9f1cc0a54bb186c2678803daafa4",
      "questionText": "How can a Big Data system be developed to enable efficient data collection, processing, storage, and sharing for industrial boilers?",
      "questionType": "Methodological",
      "relatedVariables": [
        {
          "variableName": "Big Data system",
          "variableRole": "Dependent"
        },
        {
          "variableName": "Data collection",
          "variableRole": "Independent"
        },
        {
          "variableName": "Data processing",
          "variableRole": "Independent"
        },
        {
          "variableName": "Data storage",
          "variableRole": "Independent"
        },
        {
          "variableName": "Data sharing",
          "variableRole": "Independent"
        }
      ],
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba",
      "addressesGap": "8059d7247d7a440b89c01a5693794f0e"
    },
    {
      "internal_id": "235a8fe179c049d5a4ab7f4235ef4242",
      "questionText": "Can the proposed system deliver high throughput for write operations and reasonable latency for read operations under massive user requests?",
      "questionType": "Evaluative",
      "relatedVariables": [
        {
          "variableName": "Throughput for write operations",
          "variableRole": "Dependent"
        },
        {
          "variableName": "Latency for read operations",
          "variableRole": "Dependent"
        },
        {
          "variableName": "User requests",
          "variableRole": "Independent"
        }
      ],
      "extractionConfidence": 0.85,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba",
      "addressesGap": "8059d7247d7a440b89c01a5693794f0e"
    }
  ],
  "sciknow-25x1-future-directions": [],
  "sciknow-25x1-potential-applications": [],
  "sciknow-25x1-scientific-challenges": [
    {
      "internal_id": "01ab5878f6c2473980eaf96c356c2a52",
      "challengeDescription": "High-performance AI models require extensive amounts of training data, which is a challenge for their application in improving the efficiency of industrial boilers.",
      "challengeType": "ScaleChallenge",
      "severity": "Major",
      "extractionConfidence": 0.8,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba"
    },
    {
      "internal_id": "2d05593c339547e2acb36b6fc0e58907",
      "challengeDescription": "Industrial boilers are operated in a manner where technicians directly control them, which has limitations in adapting to complex environmental changes and various operating conditions in real-time.",
      "challengeType": "ComplexityChallenge",
      "severity": "Moderate",
      "extractionConfidence": 0.7,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba"
    },
    {
      "internal_id": "c933169c13064211beac6f4b8916bac6",
      "challengeDescription": "The need to develop a Big Data system capable of storing vast amounts of data and enabling authorized users to share data for training AI models.",
      "challengeType": "ScaleChallenge",
      "severity": "Major",
      "extractionConfidence": 0.8,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "relatedProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba"
    }
  ],
  "sciknow-25x1-methodological-challenges": [],
  "sciknow-25x1-implementation-challenges": [
    {
      "internal_id": "a23a1bafbccf488dae8852de6a8593fb",
      "challengeDescription": "Insufficient storage capacity and reduced processing speed as more real-time data is added",
      "resourceConstraint": "Scale",
      "technicalHurdle": "Scalability of the database system",
      "extractionConfidence": 0.8,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "encounteredInFramework": "f87d9b78d27d4c13b69003616bca20a1"
    },
    {
      "internal_id": "d03d24ccea1042d09ca612f12148cdaa",
      "challengeDescription": "Performance degradation in large-scale concurrent write operations",
      "resourceConstraint": "Hardware",
      "technicalHurdle": "Throughput limitations under heavy load",
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "encounteredInFramework": "f87d9b78d27d4c13b69003616bca20a1"
    },
    {
      "internal_id": "9faec7064dad4c24aa5c6f6a26660216",
      "challengeDescription": "Timeout error rates sharply increase with the number of concurrent users",
      "resourceConstraint": "Hardware",
      "technicalHurdle": "Concurrency handling in processing environments",
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "encounteredInFramework": "f87d9b78d27d4c13b69003616bca20a1"
    },
    {
      "internal_id": "9639c17c907a4acca552acc488f5386c",
      "challengeDescription": "Scaling up server instances needed to enhance capacity for large-scale concurrent processing",
      "resourceConstraint": "Hardware",
      "technicalHurdle": "Server scalability to handle concurrent requests",
      "extractionConfidence": 0.85,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "encounteredInFramework": "f87d9b78d27d4c13b69003616bca20a1"
    }
  ],
  "sciknow-25x1-limitations": [
    {
      "internal_id": "0d1226c6b2e84626bcc09ee6d6ab4937",
      "limitationDescription": "The timeout error rate sharply increases to 60% when the number of threads is increased from 500 to 1000, indicating limitations in large-scale concurrent processing environments.",
      "limitationType": "ResourceConstraint",
      "impactOnFindings": "This limitation suggests that the system may not handle very high levels of concurrency effectively, which could impact the reliability and efficiency of the system under heavy loads.",
      "businessConstraints": "Businesses may need to invest in additional server instances to handle large-scale concurrent processing, which could increase operational costs and complexity.",
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "limitedFramework": "f87d9b78d27d4c13b69003616bca20a1"
    },
    {
      "internal_id": "f6018cabe912466194dc248b096e660f",
      "limitationDescription": "Performance degradation in large-scale concurrent write operations is observed as the error rate increases and throughput decreases with the number of threads.",
      "limitationType": "ResourceConstraint",
      "impactOnFindings": "The system's performance in write operations may not be as robust as required for industrial-scale applications, potentially affecting the system's overall effectiveness.",
      "businessConstraints": "Scaling up server instances to improve write operation performance could lead to higher infrastructure costs and may require more sophisticated load balancing strategies.",
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "limitedFramework": "f87d9b78d27d4c13b69003616bca20a1"
    }
  ],
  "sciknow-25x1-methodological-frameworks": [
    {
      "internal_id": "f87d9b78d27d4c13b69003616bca20a1",
      "name": "Development of Big Data System with API Authentication for Industrial Boilers",
      "description": "The study presents a methodological framework for developing a Big Data system with API authentication to enhance the efficiency of industrial boilers. The framework encompasses the collection, processing, storage, and sharing of data, leveraging distributed data processing and secure authentication protocols to protect sensitive information. The system integrates various technologies such as IoT devices, GraphQL, Kafka, Spark, Cassandra, OAuth 2.0, and Redis to enable real-time data handling and AI model training. The performance of the system is evaluated through stress tests simulating heavy loads and measuring throughput and latency.",
      "studyDesign": {
        "designType": "Simulation",
        "controlGroup": false,
        "randomization": false,
        "blinding": null,
        "timeDimension": "CrossSectional",
        "designDetails": "The study uses a simulation-based design to evaluate the performance of the proposed Big Data system. It does not involve a control group, randomization, or blinding, as it focuses on system performance rather than comparative analysis."
      },
      "variables": [],
      "procedures": [
        {
          "procedureName": "Data Collection",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Collection of real-time data from industrial boilers using IoT devices and sensors.",
              "inputs": null,
              "outputs": "Real-time boiler data",
              "parameters": {}
            },
            {
              "stepNumber": 2,
              "description": "Transmission of collected data to the GraphQL API.",
              "inputs": "Real-time boiler data",
              "outputs": "GraphQL API requests",
              "parameters": {}
            },
            {
              "stepNumber": 3,
              "description": "Transformation of data into Kafka messages.",
              "inputs": "GraphQL API requests",
              "outputs": "Kafka messages",
              "parameters": {}
            },
            {
              "stepNumber": 4,
              "description": "Sending Kafka messages to a specific topic on the Kafka broker.",
              "inputs": "Kafka messages",
              "outputs": "Data published to Kafka broker",
              "parameters": {}
            }
          ],
          "procedureDescription": "IoT devices and sensors collect real-time data from industrial boilers, which is transmitted to the GraphQL API. The data is then transformed into Kafka messages and sent to a Kafka broker."
        },
        {
          "procedureName": "Data Processing",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Consumption of data from Kafka brokers using Spark.",
              "inputs": "Data published to Kafka broker",
              "outputs": "Real-time analysis and processing",
              "parameters": {}
            },
            {
              "stepNumber": 2,
              "description": "Filtering out noise and missing values during real-time data collection.",
              "inputs": "Real-time analysis and processing",
              "outputs": "Valid data",
              "parameters": {}
            }
          ],
          "procedureDescription": "Data published to Kafka brokers is consumed by Spark for real-time analysis and processing. Filtering is applied to remove noise or missing values."
        },
        {
          "procedureName": "Data Storage",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Storage of processed data in Cassandra.",
              "inputs": "Valid data",
              "outputs": "Data stored in Cassandra",
              "parameters": {}
            }
          ],
          "procedureDescription": "The data processed by Spark is stored in Cassandra, which acts as training data for AI models and enables real-time monitoring of boiler status."
        },
        {
          "procedureName": "User Access",
          "steps": [
            {
              "stepNumber": 1,
              "description": "Retrieval of necessary data by users through the GraphQL API.",
              "inputs": "Data stored in Cassandra",
              "outputs": "Requested data",
              "parameters": {}
            },
            {
              "stepNumber": 2,
              "description": "Authentication and authorization of users using OAuth 2.0.",
              "inputs": "User access requests",
              "outputs": "Authenticated access",
              "parameters": {}
            },
            {
              "stepNumber": 3,
              "description": "Caching of user authentication information in Redis.",
              "inputs": "Authenticated access",
              "outputs": "Cached authentication information",
              "parameters": {}
            }
          ],
          "procedureDescription": "Stored data is accessed through the GraphQL API, with OAuth 2.0 ensuring security and Redis caching authentication information to reduce performance impacts."
        }
      ],
      "dataCollection": {
        "collectionMethod": "SensorReading",
        "instrumentDescription": "IoT devices and sensors are used to measure real-time data such as temperature, pressure, and fuel consumption of industrial boilers.",
        "collectionSetting": "The data collection occurs within the operational environment of industrial boilers.",
        "collectionTimeframe": "Data is collected in real-time as the boilers operate.",
        "dataRecordingFormat": null
      },
      "dataAnalysis": {
        "analysisApproach": null,
        "statisticalTests": null,
        "algorithmsUsed": null,
        "softwareDetails": null,
        "parameterSettings": null,
        "dataPreprocessingSteps": "Filtering out noise and missing values from the real-time data.",
        "summary": "The data analysis involves real-time processing of data streams using Spark, with Kafka ensuring high throughput and low latency. The processed data is stored in Cassandra for use in AI model training and real-time monitoring. Performance evaluation is conducted through stress tests measuring throughput and latency under heavy loads."
      },
      "resultsRepresentation": {
        "representationFormat": "Graph",
        "visualizationType": null,
        "reportingStandard": null,
        "summary": "The results indicate that the proposed system achieves high throughput for write operations and reasonable latency for read operations. The system's performance is visualized in figures showing the impact of increasing concurrent user requests on response times and error rates."
      },
      "reproducibilityAndSharing": {
        "dataAvailabilityStatement": null,
        "dataRepository": null,
        "codeAvailabilityStatement": null,
        "codeRepository": null,
        "protocolAvailability": null,
        "commercializationPartners": null
      },
      "extractionConfidence": 0.9,
      "paper": "d258db032e914e31a485fa23cbd58453",
      "researchProblem": "e0c94ac9704f4f2baaa3012bddb5c8ba"
    }
  ],
  "sciknow-25x1-material-tools": [
    {
      "internal_id": "c25f3e22f29347b886fe7ae80bb5444b",
      "itemName": "Hammer",
      "itemType": "Tool",
      "identifier": "HMR-001",
      "specifications": "Steel head, wooden handle, 16oz",
      "roleInProcedure": "Used to drive nails into wood",
      "extractionConfidence": 0.9,
      "usedInFrameworks": [
        "f87d9b78d27d4c13b69003616bca20a1"
      ]
    }
  ]
}