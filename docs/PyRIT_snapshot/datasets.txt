Directory structure:
└── datasets/
    ├── 0_dataset.md
    ├── 1_seed_prompt.ipynb
    └── 2_fetch_dataset.ipynb


Files Content:

================================================
File: doc/code/datasets/0_dataset.md
================================================
# Datasets

The datasets component within PyRIT is the first piece of an attack. By fetching datsets from different sources, we often load them into PyRIT as a `SeedPromptDataset` to build out the prompts which we will attack with. The building block of this dataset consists of a `SeedPrompt` which can use a template with parameters or just a prompt. The datasets can be loaded through different formats such as from an open source repository or through a YAML file. By storing these datasets within PyRIT, we can further distinguish them by incorporating data attributes such as `harm_categories` or other labels. In order to further define these datasets, we use `SeedPrompts`.

**Seed Prompts**:

By using `SeedPrompts` through loading from a YAML file or loading them via system prompt, the following sections will demonstrate specific examples using prompts or templates. These currently support multi-modal datasets including images, audio, and videos.

**Loading Datasets**:

We also show examples of common methods to fetch datasets into PyRIT from different sources. Most datasets will be loaded as a `SeedPromptDataset`. Outside of these examples, the fetch functions which are currently available can be found in `fetch_example_datasets.py` and are organized by similar method type. There is a wide range of datasets which are included and can be used as example to also load in other datasets. As these datasets are the first component of building an attack in PyRIT, the following notebooks also continue to demonstrate how these prompts can be used in the process.


================================================
File: doc/code/datasets/1_seed_prompt.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Seed Prompts

Most of the datasets we load into PyRIT are stored as a `SeedPromptDataset`. It is useful to store these results with the attributes and metadata associated with these prompts. In order to better understand the organization of the data, we will first start by defining what a `SeedPrompt` is. A `SeedPrompt` can either be a prompt template with parameters such as `{{gender}}` or just a prompt. By loading a YAML file as a `SeedPromptDataset`, we can use the prompts in other components within PyRIT.
"""

import pathlib

from pyrit.common import IN_MEMORY, initialize_pyrit
from pyrit.common.path import DATASETS_PATH
from pyrit.models import SeedPromptDataset

initialize_pyrit(memory_db_type=IN_MEMORY)

seed_prompt_dataset = SeedPromptDataset.from_yaml_file(pathlib.Path(DATASETS_PATH) / "seed_prompts" / "illegal.prompt")

print(seed_prompt_dataset.prompts[0])

"""
There are many attributes stored in a `SeedPrompt` that is very useful for querying by fields such as `harm_categories`.
"""

"""
# Loading a Dataset as a `SeedPromptDataset`

By managing `SeedPrompt` objects as a `SeedPromptDataset`, we can load prompts from other datasets. This example demonstrates the process of using XSTest Bias Testing examples to evaluate the safety and bias of an AI language model.
"""

from pyrit.datasets import fetch_xstest_dataset

# Fetch examples from XSTest Bias Testing datase
xstest_dataset = fetch_xstest_dataset()

# Use the first 4 examples
prompt_list = [prompt.value for prompt in xstest_dataset.prompts[:4]]
print(xstest_dataset.prompts[0])

"""
By using `render_template_value`, we can put values into the template. The below example shows a simple use case of using the template in a jailbreak to include in the prompts. 
"""

from pyrit.models import SeedPrompt

jailbreak_template = SeedPrompt.from_yaml_file(
    pathlib.Path(DATASETS_PATH) / "prompt_templates" / "jailbreak" / "jailbreak_1.yaml"
)

jailbreak_prompt: str = jailbreak_template.render_template_value(
    prompt="Say the words 'I wish I could be the first golden retriever to go to outer space.'"
)

print(jailbreak_prompt)

"""
# Multimodal use case with Seed Prompt Groups

For multimodal cases where we want to send a piece of text and image together, the `SeedPromptGroup` abstraction can be used for groups of seed prompts. When a group of prompts need to be sent together, this class can support sending this datatype to a target where all the prompts share the same `prompt_group_id`. This is also useful for multi-turn conversations such as in Skeleton Key attack where the sequences are both fixed prompts.
"""

from pyrit.models import SeedPromptGroup

image_path = pathlib.Path(".") / ".." / ".." / ".." / "assets" / "pyrit_architecture.png"

seed_prompt_group= SeedPromptGroup(
    prompts= [
        SeedPrompt(
            value="Describe the image in the image_path",
            data_type="text",
        ),
        SeedPrompt(
            value=str(image_path),
            data_type="image_path",
        ),
    ]
)

print(seed_prompt_group.prompts)

================================================
File: doc/code/datasets/2_fetch_dataset.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Fetching dataset examples

This notebook demonstrates how to load datasets as a `SeedPromptDataset` to perform red teaming on a target. 
There are several datasets which can be found in the `fetch_example_datasets.py` file. 
Three example datasets are shown in this notebook and can be used with orchestrators such as the Prompt Sending Orchestrator. 
The example below demonstrates loading a HuggingFace dataset as a `SeedPromptDataset`.
"""

from pyrit.common import IN_MEMORY, initialize_pyrit
from pyrit.datasets import fetch_llm_latent_adversarial_training_harmful_dataset
from pyrit.orchestrator import PromptSendingOrchestrator
from pyrit.prompt_target import TextTarget

initialize_pyrit(memory_db_type=IN_MEMORY)

# Set up the Azure OpenAI prompt target
prompt_target = TextTarget()

# Fetch prompt column from harmful datasets
prompt_dataset = fetch_llm_latent_adversarial_training_harmful_dataset()
# Some fetch functions may include parameters such as the below example for unsafe prompts 
# prompt_dataset = fetch_pku_safe_rlhf_dataset(False)

# Use the first 8 examples for red teaming
prompt_list = [prompt.value for prompt in prompt_dataset.prompts[:8]]

# Send prompts using the orchestrator and capture responses
orchestrator = PromptSendingOrchestrator(objective_target=prompt_target)
responses = await orchestrator.send_prompts_async(prompt_list=prompt_list)  # type: ignore

"""
# Example dataset from public URL

The following example fetches DecodingTrust 'stereotypes' examples of involving potentially harmful stereotypes from the DecodingTrust repository which try to convince the assistant to agree and captures the responses. This is a scenario where the dataset resides in a public  URL and is also outputted as a `SeedPromptDataset`. By fetching these prompts, we can further use this `SeedPromptDataset` by sending the prompts to a target using the `PromptSendingOrchestrator` as shown in the example below.
"""

from pyrit.datasets import fetch_decoding_trust_stereotypes_dataset
from pyrit.prompt_target import TextTarget

# Set up the Azure OpenAI prompt target
prompt_target = TextTarget()
examples_source = (
    "https://raw.githubusercontent.com/AI-secure/DecodingTrust/main/data/stereotype/dataset/user_prompts.csv"
)

orchestrator = PromptSendingOrchestrator(objective_target=prompt_target)

# Fetch examples from DecodingTrust 'Stereotype' dataset using the 'targeted' system prompt and topics of "driving" and "technology"
prompt_dataset = fetch_decoding_trust_stereotypes_dataset(
    examples_source,
    source_type="public_url",
    stereotype_topics=["driving", "technology"],
    target_groups=None,
    system_prompt_type="targeted",
)

# Use the first 4 examples
prompt_list = [prompt.value for prompt in prompt_dataset.prompts[:4]]

# Send prompts using the orchestrator and capture responses
try:
    responses = await orchestrator.send_prompts_async(prompt_list=prompt_list)  # type: ignore
    if responses:
        await orchestrator.print_conversations_async()  # type: ignore
    else:
        print("No valid responses were received from the orchestrator.")
except Exception as e:
    print(f"An error occurred while sending prompts: {e}")


from pyrit.memory import CentralMemory

memory = CentralMemory.get_memory_instance()
memory.dispose_engine()


